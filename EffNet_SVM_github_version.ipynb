{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ncz1oqTUety"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Attention\n",
        "# from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S, preprocess_input\n",
        "from google.colab.patches import cv2_imshow\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "# import imutils\n",
        "import time\n",
        "import cv2\n",
        "from cuml import SVC\n",
        "# from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "2zyfvDn5UoE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "FWJjGMnUUqSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/drive/MyDrive/APTOS 2019 dataset'\n",
        "train_dir = os.path.join(base_dir, 'train_images/train_images/')\n",
        "validation_dir = os.path.join(base_dir, 'val_images/val_images/')\n",
        "test_dir = os.path.join(base_dir, 'test_images/test_images/')"
      ],
      "metadata": {
        "id": "KCy70rdzUtzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fFgflXqeav7"
      },
      "outputs": [],
      "source": [
        "print(os.listdir(train_dir))\n",
        "print(os.listdir(validation_dir))\n",
        "print(os.listdir(test_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXs8v6OsX6hI"
      },
      "outputs": [],
      "source": [
        "train_path = \"/content/drive/MyDrive/APTOS 2019 dataset/train_images/train_images/\"\n",
        "valid_path = \"/content/drive/MyDrive/APTOS 2019 dataset/val_images/val_images/\"\n",
        "test_path = \"/content/drive/MyDrive/APTOS 2019 dataset/test_images/test_images/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GK-GTr_fchk"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 2\n",
        "epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiGkU21Lc2vt"
      },
      "outputs": [],
      "source": [
        "img_augmentation = Sequential(\n",
        "    [\n",
        "        tf.keras.layers.RandomRotation(factor=(-0.15, 0.15)),\n",
        "        tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "        tf.keras.layers.RandomFlip(),\n",
        "        tf.keras.layers.RandomContrast(factor=0.1),\n",
        "    ],\n",
        "    name=\"img_augmentation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oI5fJLZFgkUT"
      },
      "outputs": [],
      "source": [
        "def unfreeze_model(model):\n",
        "    # Unfreeze the top 10 layers while leaving BatchNorm layers frozen for fine-tuning\n",
        "    for layer in model.layers[-10:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxFAoEmwgt-L"
      },
      "outputs": [],
      "source": [
        "def test_model(model,test_batches):\n",
        "    #Testing the Model\n",
        "    test_labels = test_batches.classes\n",
        "    print(\"Test Labels\",test_labels)\n",
        "    print(test_batches.class_indices)\n",
        "\n",
        "    predictions = model.predict(test_batches,steps=len(test_batches),verbose=0)\n",
        "\n",
        "    acc = 0\n",
        "    for i in range(len(test_labels)):\n",
        "        actual_class = test_labels[i]\n",
        "        if predictions[i][actual_class] > 0.5:\n",
        "            acc += 1\n",
        "    print(\"Accuarcy:\",(acc/len(test_labels))*100,\"%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title create train, test and valid data\n",
        "def load_data():\n",
        "    train = pd.read_csv('/content/drive/MyDrive/APTOS 2019 dataset/train_1 - 2 class.csv', encoding='utf-8')\n",
        "    test = pd.read_csv('/content/drive/MyDrive/APTOS 2019 dataset/test - 2 class.csv', encoding='utf-8')\n",
        "    valid = pd.read_csv('/content/drive/MyDrive/APTOS 2019 dataset/val - 2 class.csv', encoding='utf-8')\n",
        "\n",
        "    train_dir = os.path.join('/content/drive/MyDrive/APTOS 2019 dataset/train_images/train_images')\n",
        "    test_dir = os.path.join('/content/drive/MyDrive/APTOS 2019 dataset/test_images/test_images')\n",
        "    valid_dir = os.path.join('/content/drive/MyDrive/APTOS 2019 dataset/val_images/val_images')\n",
        "\n",
        "    # Construct file paths directly within function:\n",
        "    train['file_path'] = [os.path.join(train_dir, f'{id_code}.png') for id_code in train['id_code']]\n",
        "    test['file_path'] = [os.path.join(test_dir, f'{id_code}.png') for id_code in test['id_code']]\n",
        "    valid['file_path'] = [os.path.join(valid_dir, f'{id_code}.png') for id_code in valid['id_code']]\n",
        "\n",
        "    # Construct file names using list comprehensions:\n",
        "    train['train_images'] = [id_code + \".png\" for id_code in train['id_code']]\n",
        "    test['test_images'] = [id_code + \".png\" for id_code in test['id_code']]\n",
        "    valid['val_images'] = [id_code + \".png\" for id_code in valid['id_code']]\n",
        "\n",
        "    train['diagnosis'] = train['diagnosis'].astype(str)\n",
        "    test['diagnosis'] = test['diagnosis'].astype(str)\n",
        "    valid['diagnosis'] = valid['diagnosis'].astype(str)\n",
        "\n",
        "    return train, test, valid"
      ],
      "metadata": {
        "id": "yMlA7VkkU62n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuFcrDVed3Ak"
      },
      "outputs": [],
      "source": [
        "def inference_data():\n",
        "  inference = pd.read_csv('/content/drive/MyDrive/APTOS 2019 dataset/HRF fundus image database/Collective labels.txt', sep = '\\t')\n",
        "\n",
        "  inference_dir = os.path.join('/content/drive/MyDrive/APTOS 2019 dataset/HRF fundus image database')\n",
        "\n",
        "  inference['file_name'] = [os.path.join(inference_dir, f'{file_name}') for file_name in inference['file_name']]\n",
        "\n",
        "  # inference['inference_images'] = [file_name + \".png\" for file_name in inference[\"file_name\"]]\n",
        "\n",
        "  inference['label'] = inference['label'].astype(str)\n",
        "\n",
        "  return inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRsZcjjp7MxX"
      },
      "outputs": [],
      "source": [
        "def inference_EyePACS():\n",
        "  inference = pd.read_csv('/content/drive/MyDrive/APTOS 2019 dataset/EyePACS labels - trainLabels.csv', sep = ',')\n",
        "\n",
        "  inference_dir = os.path.join('/content/drive/MyDrive/APTOS 2019 dataset/EyePACS Subset')\n",
        "\n",
        "  inference['image'] = [os.path.join(inference_dir, f'{file_name}') for file_name in inference['image']]\n",
        "\n",
        "  inference['image'] = [file_name + \".jpeg\" for file_name in inference[\"image\"]]\n",
        "\n",
        "  inference['diagnosis'] = inference['diagnosis'].astype(str)\n",
        "\n",
        "  return inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyggspv_-h0X"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(img_path):\n",
        "  img = load_img(img_path, target_size=(224, 224))\n",
        "  img_array = img_to_array(img)\n",
        "  img_array = np.expand_dims(img_array, axis=0)\n",
        "  return preprocess_input(img_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7t4V5EYA6Re"
      },
      "outputs": [],
      "source": [
        "# @title Compute GradCAM\n",
        "def compute_gradcam(model, img_array, last_conv_layer_name, class_idx):\n",
        "    grad_model = Model(\n",
        "        inputs=[model.inputs],\n",
        "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array,training=False)\n",
        "        class_channel = preds[:, class_idx]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9XmwLUp-pKx"
      },
      "outputs": [],
      "source": [
        "# @title Display the GradCAM heatmap superimposed on top of image\n",
        "def display_heatmap(original_img, heatmap, alpha=0.5):\n",
        "    img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "    superimposed_img = heatmap * alpha + img\n",
        "    superimposed_img = np.uint8(superimposed_img)\n",
        "\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(superimposed_img)\n",
        "    plt.title('Grad-CAM Heatmap')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display heatmap\n",
        "def display_heatmap1(heatmap):\n",
        "    # Resize the heatmap to a higher resolution\n",
        "    heatmap_resized = cv2.resize(heatmap, (224, 224))  # Adjust the size as needed\n",
        "    # Display the heatmap with improved granularity\n",
        "    plt.imshow(heatmap_resized, cmap='jet', interpolation='bilinear')\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "XjjQcbBxWLKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "obOhkMp0g3LI"
      },
      "outputs": [],
      "source": [
        "# @title Training\n",
        "if __name__ == \"__main__\":\n",
        "    train_df, test_df, valid_df = load_data()\n",
        "    model = build_EfficientNetV2S_model_SVM_without_attention(NUM_CLASSES)\n",
        "    unfreeze_model(model)\n",
        "\n",
        "    train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input).flow_from_dataframe(\n",
        "        dataframe=train_df, x_col='file_path', y_col='diagnosis', target_size=(224,224), batch_size=32)\n",
        "    valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input).flow_from_dataframe(\n",
        "        dataframe=valid_df, x_col='file_path', y_col='diagnosis', target_size=(224,224), batch_size=32)\n",
        "    test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input).flow_from_dataframe(\n",
        "        dataframe=test_df, x_col='file_path', y_col='diagnosis', target_size=(224,224), batch_size=32, shuffle=False)\n",
        "\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-4)\n",
        "    history = model.fit(train_batches, epochs=epochs, validation_data=valid_batches, verbose=1,callbacks=[early_stopping,reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = keras.models.load_model('/content/drive/MyDrive/APTOS 2019 dataset/Saved models/1) Normal softmax classification with EfficientNetV2S with dropout.h5')\n",
        "# model.save(\"/content/drive/MyDrive/APTOS 2019 dataset/Saved models/1) Normal softmax classification with EfficientNetV2S with dropout.h5\")"
      ],
      "metadata": {
        "id": "7qdpo5BBVQHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Accuracy-Loss plot\n",
        "def plot_accuracy_loss(history):\n",
        "    # Accuracy plot\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "    # Loss plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(loc='upper left')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_accuracy_loss(history)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "CNZI6oC3VZEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inference on test data\n",
        "for i in range(len(test_df)):\n",
        "  img_path = test_df['file_path'][i]\n",
        "  # original_img = cv2.imread(img_path)\n",
        "  img_array = preprocess_image(img_path)\n",
        "  predicted_label = model.predict(img_array)\n",
        "  predicted_label = np.argmax(predicted_label)\n",
        "  # last_conv_layer_name = \"top_activation\"  # Replace with the actual last conv layer name of your model\n",
        "  class_idx = predicted_label  # Replace with the actual class index you want to visualize\n",
        "  actual_label = test_df['diagnosis'][i]\n",
        "  print(i,actual_label, predicted_label)"
      ],
      "metadata": {
        "id": "gDG17m4qVqeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_batches)"
      ],
      "metadata": {
        "id": "0fF4OkElV1Tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the Model\n",
        "test_model(model,test_batches)"
      ],
      "metadata": {
        "id": "ApuacXvlV3eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_test = (model.predict(test_batches) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "id": "1rXo9ZVsV-ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n\", classification_report(test_batches.labels, softmax_test.argmax(axis=1)))"
      ],
      "metadata": {
        "id": "WwIdcA5yWBS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cms = confusion_matrix(test_batches.labels, softmax_test.argmax(axis=1))  #top_dropout softmax\n",
        "sns.heatmap(cms, annot=True, cbar=False, fmt='d')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Inference Confusion Matrix')"
      ],
      "metadata": {
        "id": "0MBhpc6CWDUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 253\n",
        "img_path = test_df['file_path'][index]\n",
        "original_img = cv2.imread(img_path)\n",
        "img_array = preprocess_image(img_path)\n",
        "predicted_label = model.predict(img_array)\n",
        "predicted_label = np.argmax(predicted_label)\n",
        "last_conv_layer_name = \"top_conv\"  # Replace with the actual last conv layer name of model\n",
        "actual_label = test_df['diagnosis'][index]\n",
        "class_idx = predicted_label  # Replace with the actual class index to be visualized\n",
        "print(actual_label, predicted_label)\n",
        "heatmap = compute_gradcam(model, img_array, last_conv_layer_name, class_idx)\n",
        "display_heatmap(original_img, heatmap)\n",
        "display_heatmap1(heatmap)"
      ],
      "metadata": {
        "id": "Grze-GlsWgYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model,test_batches)"
      ],
      "metadata": {
        "id": "Qr-ARkvOWqWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_pred = (model.predict(test_batches) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "id": "xWto1Bs-WseX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n\", classification_report(test_batches.labels, softmax_pred.argmax(axis=1)))"
      ],
      "metadata": {
        "id": "f6t9XtWiWuvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cms = confusion_matrix(test_batches.labels, softmax_pred.argmax(axis=1))  #top_dropout softmax\n",
        "sns.heatmap(cms, annot=True, cbar=False, fmt='d')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix')"
      ],
      "metadata": {
        "id": "hYDBYUHJWwhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "eD4mcDF7XK0g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rcq4TNhu9CXH"
      },
      "outputs": [],
      "source": [
        "# Collect data from the generator\n",
        "X_train, y_train = [], []\n",
        "for _ in range(len(train_batches)):\n",
        "    images, labels = next(train_batches)\n",
        "    X_train.append(images)\n",
        "    y_train.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVcREamR9Do4"
      },
      "outputs": [],
      "source": [
        "# Convert lists to arrays\n",
        "X_train = np.vstack(X_train)\n",
        "y_train = np.vstack(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "AxEsE6n8DXGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qDFPWQL9EsO"
      },
      "outputs": [],
      "source": [
        "# Reshape X_train to be 2D (necessary for SVM)\n",
        "X_train1 = X_train.reshape(X_train.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYwflwXoAtDU"
      },
      "outputs": [],
      "source": [
        "X_train1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ob5NYcRABphV"
      },
      "outputs": [],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCkj_jhDDgIy"
      },
      "outputs": [],
      "source": [
        "# Collect data from the generator\n",
        "X_test, y_test = [], []\n",
        "for _ in range(len(test_batches)):\n",
        "    images, labels = next(test_batches)\n",
        "    X_test.append(images)\n",
        "    y_test.append(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfTT_Sq0D42C"
      },
      "outputs": [],
      "source": [
        "# Convert lists to arrays\n",
        "X_test = np.vstack(X_test)\n",
        "y_test = np.vstack(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "MiaBckmtwFZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xz3bDaZJERDT"
      },
      "outputs": [],
      "source": [
        "# Reshape X_train to be 2D (necessary for SVM)\n",
        "X_test1 = X_test.reshape(X_test.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FAMU2iiERDU"
      },
      "outputs": [],
      "source": [
        "X_test1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_w1u2dXbERDU"
      },
      "outputs": [],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_2lRh-i9F5X"
      },
      "outputs": [],
      "source": [
        "# Initialize and train the SVC with verbose output\n",
        "start = time.time()\n",
        "svc = SVC(verbose=True,kernel='rbf')\n",
        "svc.fit(X_train1, y_train.argmax(axis=1))  # Use argmax to get class indices if y_train is one-hot encoded\n",
        "print('Running time: %.4f seconds' % (time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9e6Oz2SVB6U"
      },
      "outputs": [],
      "source": [
        "# Get predictions from SVC using test features\n",
        "predictions_test = svc.predict(X_test1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_test = accuracy_score(y_test.argmax(axis=1), predictions_test)\n",
        "print(\"Testing Accuracy using SVM with Feature Extraction:\", accuracy_test)"
      ],
      "metadata": {
        "id": "WBV1O2da2T-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_batches.labels, predictions_test))"
      ],
      "metadata": {
        "id": "FEFgGz4HXb4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmsvm = confusion_matrix(test_batches.labels, predictions_test)\n",
        "sns.heatmap(cmsvm, annot=True, cbar=False, fmt='d')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix')"
      ],
      "metadata": {
        "id": "UT6Kt6qwXeHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaePrNCQh9Mh"
      },
      "outputs": [],
      "source": [
        "# @title EffNet-SVM classifier\n",
        "from tensorflow.python.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHBZSpnthtXn"
      },
      "outputs": [],
      "source": [
        "model1 = tf.keras.Model(inputs=model.input, outputs=model.get_layer('top_conv').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl0ynfbqjwhK"
      },
      "outputs": [],
      "source": [
        "features_array_train1 = model1.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_array_train1_reshape = features_array_train1.reshape(features_array_train1.shape[0], -1)"
      ],
      "metadata": {
        "id": "6-XkBNaU8130"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXWMsPjupvyj"
      },
      "outputs": [],
      "source": [
        "features_array_test1 = model1.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_array_test1_reshape = features_array_test1.reshape(features_array_test1.shape[0], -1)"
      ],
      "metadata": {
        "id": "nLKDx3QR-sdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test1 = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "sHnG8RX9Lda0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZZctVEymS2y"
      },
      "outputs": [],
      "source": [
        "clf = SVC(verbose=True,kernel='rbf')\n",
        "start = time.time()\n",
        "# for _ in range(5):\n",
        "clf.fit(features_array_train1_reshape, y_train.argmax(axis=1))   #Learned from training! SAVE THIS!!!! Edt : saved!\n",
        "preds1 = clf.predict(features_array_test1_reshape)\n",
        "print('Running time: %.4f seconds' % (time.time()-start))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# with open('/content/drive/MyDrive/APTOS 2019 dataset/Saved models/cuML trained EffNet-SVM model.pkl', 'wb') as f:\n",
        "#     pickle.dump(clf, f)\n",
        "\n",
        "# Load the model from the file using pickle\n",
        "# with open('/content/drive/MyDrive/APTOS 2019 dataset/Saved models/cuML trained EffNet-SVM model.pkl', 'rb') as f:\n",
        "#     clf = pickle.load(f)\n",
        "\n",
        "# Use the loaded model for predictions\n",
        "# predictions = clf_loaded.predict(features_array_test1_reshape)"
      ],
      "metadata": {
        "id": "X66teX9lYFUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_score(y_test.argmax(axis=1), preds1))  #top_dropout"
      ],
      "metadata": {
        "id": "d5q7JeNrYPdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(test_batches.labels, preds1)  #top_dropout\n",
        "sns.heatmap(cm, annot=True, cbar=False, fmt='d')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix')"
      ],
      "metadata": {
        "id": "xXWsK5aPYTio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(test_batches.labels, preds1))"
      ],
      "metadata": {
        "id": "-XoRS8AKYVs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Inference on inference data using EffNet-SVM - Inference time\n",
        "\n",
        "# infer_df = inference_data()\n",
        "infer_df = inference_EyePACS()\n",
        "inference_times = []\n",
        "\n",
        "for _ in range(5):\n",
        "  for i in range(len(infer_df)):\n",
        "    # img_path = infer_df['file_name'][i]\n",
        "    img_path = infer_df['image'][i]\n",
        "\n",
        "    if not os.path.exists(img_path):\n",
        "      # print(f\"Image not found: {img_path}. Skipping...\")\n",
        "      continue\n",
        "    try:\n",
        "      # original_img = cv2.imread(img_path)\n",
        "      img_array = preprocess_image(img_path)\n",
        "      start_time = time.time()\n",
        "      predicted_label = model1.predict(img_array)\n",
        "      preds_inference = clf.predict(predicted_label.reshape(predicted_label.shape[0], -1))\n",
        "      end_time = time.time()\n",
        "      inference_time = end_time - start_time\n",
        "      inference_times.append(inference_time)\n",
        "      # last_conv_layer_name = \"top_conv\"  # Replace with the actual last conv layer name of your model\n",
        "      # class_idx = predicted_label  # Replace with the actual class index you want to visualize\n",
        "      # actual_label = infer_df['label'][i]\n",
        "      actual_label = infer_df['diagnosis'][i]\n",
        "      print(i,actual_label, preds_inference)\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error processing image {img_path}: {e}\")\n",
        "      continue\n",
        "\n",
        "sum(inference_times) / len(inference_times)"
      ],
      "metadata": {
        "id": "9NvY9KW4Yi0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.efficientnet_v2.preprocess_input).flow_from_dataframe(\n",
        "    dataframe=infer_df, x_col='image', y_col='diagnosis', target_size=(224,224), batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "drwRsGpAYros"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(inference_batches)"
      ],
      "metadata": {
        "id": "qHwb4BP9YtKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(model,inference_batches)"
      ],
      "metadata": {
        "id": "D6RyGTyaY9mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_infer = (model.predict(inference_batches) > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "id": "vTzOFaGyZcjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n\", classification_report(inference_batches.labels, softmax_infer.argmax(axis=1)))"
      ],
      "metadata": {
        "id": "fic2-B6pZeRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cms = confusion_matrix(inference_batches.labels, softmax_infer.argmax(axis=1))  #top_dropout softmax\n",
        "sns.heatmap(cms, annot=True, cbar=False, fmt='d')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Inference Confusion Matrix')"
      ],
      "metadata": {
        "id": "yXJQnyogZgBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visual metrics"
      ],
      "metadata": {
        "id": "1nV3QLihZyjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ROC curve\n",
        "def plot_roc_curves(y_true, y_pred_probas, labels):\n",
        "    plt.figure()\n",
        "    for i in range(len(y_pred_probas)):\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_pred_probas[i])\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, lw=2, label=f'{labels[i]} (area = {roc_auc:.5f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "y_true2 = test_batches.labels\n",
        "y_pred_probas = [softmax_pred.argmax(axis=1),\n",
        "    predictions_test,\n",
        "    preds1]\n",
        "labels = ['Softmax', 'SVC(RBF)', 'EffNetV2S-SVC']\n",
        "\n",
        "plot_roc_curves(y_true2, y_pred_probas, labels)"
      ],
      "metadata": {
        "id": "qIoWHXN2Z0Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRdZD5vIKdVO"
      },
      "outputs": [],
      "source": [
        "# @title Precision-Recall curve\n",
        "def plot_precision_recall_curves(y_true, y_pred_probas, labels):\n",
        "    plt.figure()\n",
        "    for i in range(len(y_pred_probas)):\n",
        "        precision, recall, _ = precision_recall_curve(y_true, y_pred_probas[i])\n",
        "        pr_auc = auc(recall, precision)\n",
        "        plt.plot(recall, precision, lw=2, label=f'{labels[i]} (area = {pr_auc:.5f})')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "y_true2 = test_batches.labels\n",
        "y_pred_probas = [softmax_pred.argmax(axis=1),\n",
        "    predictions_test,\n",
        "    preds1]\n",
        "labels = ['Softmax', 'SVC(RBF)', 'EffNetV2S-SVC']\n",
        "\n",
        "plot_precision_recall_curves(y_true2, y_pred_probas, labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calibration curve\n",
        "def plot_calibration_curves(y_true, y_pred_probas, labels):\n",
        "    plt.figure()\n",
        "    for i in range(len(y_pred_probas)):\n",
        "        prob_true, prob_pred = calibration_curve(y_true, y_pred_probas[i], n_bins=10)\n",
        "        plt.plot(prob_pred, prob_true, marker='o', label=labels[i])\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--', color='black')\n",
        "    plt.xlabel('Predicted Probabilities')\n",
        "    plt.ylabel('True Probabilities')\n",
        "    plt.title('Calibration Curves')\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "y_true2 = test_batches.labels\n",
        "y_pred_probas = [softmax_pred.argmax(axis=1),\n",
        "    predictions_test,\n",
        "    preds1]\n",
        "labels = ['Softmax', 'SVC(RBF)', 'EffNetV2S-SVC']\n",
        "\n",
        "plot_calibration_curves(y_true2, y_pred_probas, labels)"
      ],
      "metadata": {
        "id": "-2PEFVora2qU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}